{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> ⛏ PARSING DATA FROM TWITTER\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> IMPORTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import OAuthHandler\n",
    "from tweepy import API\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "import pandas as pd\n",
    "import json\n",
    "import json\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "\n",
    "# API set-ups for the use of Twitter API\n",
    "# Insert your keys and tokens below\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_token_secret = ''\n",
    "\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "\n",
    "\n",
    "def get_tweets(listOfTweets, keyword, numOfTweets, data_since, data_until):\n",
    "    for tweet in tw.Cursor(api.search, q=keyword+' -filter:retweets', since=data_since, until=data_until, lang='ua').items(numOfTweets):\n",
    "        dict_ = {\n",
    "                 'Keywords': keyword,\n",
    "                 'User Name': tweet.user.name,\n",
    "                 'Screen Name': tweet.user.screen_name,\n",
    "                 'Tweet Created at': tweet.created_at,\n",
    "                 'Tweet Text': tweet.text,\n",
    "                 'Location': tweet.user.location,\n",
    "                 'Likes': tweet.favorite_count,\n",
    "                 'Retweets': tweet.retweet_count\n",
    "                 }\n",
    "        listOfTweets.append(dict_)\n",
    "    return listOfTweets\n",
    "\n",
    "list_1 = []\n",
    "numberOfPosts = 100\n",
    "Start_date = '2020-03-22'\n",
    "End_date = '2021-06-07'\n",
    "hashtags = 'новини політика'\n",
    "\n",
    "get_tweets(list_1, hashtags, numberOfPosts, Start_date, End_date)\n",
    "result_df = pd.DataFrame(list_1)   \n",
    "\n",
    "data = result_df[['Tweet Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('desktop/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [x for x in data['Tweet Text'].iloc[0:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖➖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = result_df[['Tweet Text']]\n",
    "l =[data['Tweet Text'].iloc[6]]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df.to_csv('desktop/Wheat_Tweets.csv', index=None)\n",
    "#df = pd.read_csv('desktop/Wheat_Tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> ⛏ PARSING DATA FROM FACEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install facebook-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = facebook.GraphAPI(access_token=\"EAAJOBdEMUHMBAEBsVHQ7ZAicqMpGPi0DzuYfwL2DchU4ZCaUkgC4Bas4nWvsZCjr8kgVgISr4Aqm8N5fKVRPVH3UwPNWsgv2phN6n6xRHaKEbWSAQy29JKkZB7a1xkyejKxp190Sp9J8lBSerIYt8aACmJ0gAJCBaBqgUiS1j4cBix8DjjZBP\", version=\"2.12\")\n",
    "\n",
    "# Get the message from a post.\n",
    "# post = graph.get_object(id='post_id', fields='message')\n",
    "post = graph.get_object(id='https://www.facebook.com/permalink.php?story_fbid=928658477469205&id=836783153323405&__xts__[0]=68.ARAE6omhF-UgfWRI7iW_P5sU7S4vdfpwi91eXqkBjxABTuIV8YtbmPDmgvQ0WJYT0FdPp9tzTXcLWR9iPOc_Oal4PJZvL_2q5HzdUzoRZJ7tRcTVJ1OiE6OD7E0XWdtWBHomsQqBPi0c2f45-seEYDmiDvLRnIYHw4x7saF2-sIA1M0DWSkFjf0Cxe5CK9vhHgZc6j9dyntiUjtzUFdOYWrU0dvAvJ9lY6GwXjQPntbi46PO6_Lnvi9et3iUav3EaIPG8LBE-dD1o6N9AN3fxcgIYQt4AwX898UYs5Zp2iUbcKCSrTS605izIfBRROtuX_FqUgecNyEdzMzWhO0&__tn__=-R', fields='message')\n",
    "print(post['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️⛔️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not working, there are some issues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SListener(StreamListener):\n",
    "    def __init__(self, api = None, fprefix = 'streamer'):\n",
    "        self.api = api or API()\n",
    "        self.counter = 0\n",
    "        self.fprefix = fprefix\n",
    "        self.output  = open('%s_%s.json' % (self.fprefix, time.strftime('%Y%m%d-%H%M%S')), 'w')\n",
    "\n",
    "\n",
    "    def on_data(self, data):\n",
    "        if  'in_reply_to_status' in data:\n",
    "            self.on_status(data)\n",
    "        elif 'delete' in data:\n",
    "            delete = json.loads(data)['delete']['status']\n",
    "            if self.on_delete(delete['id'], delete['user_id']) is False:\n",
    "                return False\n",
    "        elif 'limit' in data:\n",
    "            if self.on_limit(json.loads(data)['limit']['track']) is False:\n",
    "                return False\n",
    "        elif 'warning' in data:\n",
    "            warning = json.loads(data)['warnings']\n",
    "            print(\"WARNING: %s\" % warning['message'])\n",
    "            return\n",
    "\n",
    "\n",
    "    def on_status(self, status):\n",
    "        self.output.write(status)\n",
    "        self.counter += 1\n",
    "        if self.counter >= 20000:\n",
    "            self.output.close()\n",
    "            self.output  = open('%s_%s.json' % (self.fprefix, time.strftime('%Y%m%d-%H%M%S')), 'w')\n",
    "            self.counter = 0\n",
    "        return\n",
    "\n",
    "\n",
    "    def on_delete(self, status_id, user_id):\n",
    "        print(\"Delete notice\")\n",
    "        return\n",
    "\n",
    "\n",
    "    def on_limit(self, track):\n",
    "        print(\"WARNING: Limitation notice received, tweets missed: %d\" % track)\n",
    "        return\n",
    "\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        print('Encountered error with status code:', status_code)\n",
    "        return \n",
    "\n",
    "\n",
    "    def on_timeout(self):\n",
    "        print(\"Timeout, sleeping for 60 seconds...\")\n",
    "        time.sleep(60)\n",
    "        return \n",
    "\n",
    "# Consumer key authentication\n",
    "auth = OAuthHandler('wPIU4mm0Xt9RHpkioE8XiUjR2', 'T6zb1DKkj2WNC9F5PjpLtkX4txwsWoKLJme5LTaXSWV0LTHBQP')\n",
    "\n",
    "# Access key authentication\n",
    "auth.set_access_token('1357116781022838784-HpmRSEGOYXrRd02GZVHUltsZFeHHr2', '16VV7KEKMDokq7hIBMbBNh0DjCsNivEMAvTVA7p15gHNX')\n",
    "\n",
    "# Set up the API with the authentication handler\n",
    "api = API(auth)\n",
    "\n",
    "# Set up words to track\n",
    "def track(pattern,sourse):\n",
    "    keywords_to_track = re.findall(pattern + r'\\w*',sourse)\n",
    "    return keywords_to_track\n",
    "\n",
    "# Instantiate the SListener object \n",
    "listen = SListener(api)\n",
    "\n",
    "# Instantiate the Stream object\n",
    "stream = Stream(auth, listen)\n",
    "\n",
    "# Begin collecting data\n",
    "stream.filter()\n",
    "#track = track(pattern,sourse)\n",
    "\n",
    "def flatten_tweets(tweets_json):\n",
    "    \"\"\" Flattens out tweet dictionaries so relevant JSON\n",
    "        is in a top-level dictionary.\"\"\"\n",
    "    tweets_list = []\n",
    "    \n",
    "    # Iterate through each tweet\n",
    "    for tweet in tweets_json:\n",
    "        tweet_obj = json.loads(tweet)\n",
    "    \n",
    "        # Store the user screen name in 'user-screen_name'\n",
    "        tweet_obj['user-screen_name'] = tweet_obj['user']['screen_name']\n",
    "    \n",
    "        # Check if this is a 140+ character tweet\n",
    "        if 'extended_tweet' in tweet_obj:\n",
    "            # Store the extended tweet text in 'extended_tweet-full_text'\n",
    "            tweet_obj['extended_tweet-full_text'] = tweet_obj['extended_tweet']['full_text']\n",
    "    \n",
    "        if 'retweeted_status' in tweet_obj:\n",
    "            # Store the retweet user screen name in 'retweeted_status-user-screen_name'\n",
    "            tweet_obj['retweeted_status-user-screen_name'] = tweet_obj['retweeted_status']['user']['screen_name']\n",
    "\n",
    "            # Store the retweet text in 'retweeted_status-text'\n",
    "            tweet_obj['retweeted_status-text'] = tweet_obj['retweeted_status']['text']\n",
    "            \n",
    "        tweets_list.append(tweet_obj)\n",
    "    return tweets_list\n",
    "\n",
    "# Flatten the tweets and store in `tweets`\n",
    "tweets = flatten_tweets(collected_data)\n",
    "\n",
    "# Create a DataFrame from `tweets`\n",
    "ds_tweets = pd.DataFrame(tweets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
